{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from gptsmartfunc.func_json_extractor import function_metadata_decorator, extract_function_metadata\n",
    "from gptsmartfunc.openai_service import OpenAIService, FunctionSpec\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather example - non naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('location', <Parameter \"location\">), ('unit', <Parameter \"unit='fahrenheit'\">)]) location\n",
      "OrderedDict([('location', <Parameter \"location\">), ('unit', <Parameter \"unit='fahrenheit'\">)]) unit\n",
      "get_current_weather\n",
      "[{'role': 'user', 'content': \"What's the weather like in New York?\"}, <OpenAIObject at 0x1de735831a0> JSON: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": \"{\\n\\\"location\\\": \\\"New York\\\"\\n}\"\n",
      "  }\n",
      "}, {'role': 'function', 'name': 'get_current_weather', 'content': '{\"location\": \"New York\", \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'}]\n",
      "{\n",
      "  \"id\": \"chatcmpl-7ePe7213NgnTjClwhdVUtNaOUnF0X\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1689866059,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The current weather in New York is sunny and windy with a temperature of 72\\u00b0F.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 72,\n",
      "    \"completion_tokens\": 18,\n",
      "    \"total_tokens\": 90\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@function_metadata_decorator\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "function_specs = [\n",
    "    FunctionSpec(\n",
    "        func_ref=get_current_weather,\n",
    "        parameters=get_current_weather.metadata\n",
    "        # parameters=extract_function_metadata(get_current_weather)\n",
    "    )\n",
    "]\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai_service = OpenAIService(openai, function_specs=function_specs)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in New York?\"}\n",
    "]\n",
    "\n",
    "response = openai_service.call_function(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('n', <Parameter \"n: 'int' = 5\">)]) n\n",
      "head\n",
      "OrderedDict([('n', <Parameter \"n: 'int' = 5\">)]) n\n",
      "tail\n",
      "OrderedDict([('percentiles', <Parameter \"percentiles=None\">), ('include', <Parameter \"include=None\">), ('exclude', <Parameter \"exclude=None\">)]) percentiles\n",
      "OrderedDict([('percentiles', <Parameter \"percentiles=None\">), ('include', <Parameter \"include=None\">), ('exclude', <Parameter \"exclude=None\">)]) include\n",
      "OrderedDict([('percentiles', <Parameter \"percentiles=None\">), ('include', <Parameter \"include=None\">), ('exclude', <Parameter \"exclude=None\">)]) exclude\n",
      "describe\n",
      "[{'role': 'user', 'content': \"What's the head of the dataframe?\"}, <OpenAIObject at 0x1de73ae22a0> JSON: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"head\",\n",
      "    \"arguments\": \"{}\"\n",
      "  }\n",
      "}, {'role': 'function', 'name': 'head', 'content': '        State  Number of Solar Plants  Installed Capacity (MW)  \\\\\\n0  California                     289                     4395   \\n1     Arizona                      48                     1078   \\n2      Nevada                      11                      238   \\n3  New Mexico                      33                      261   \\n4    Colorado                      20                      118   \\n\\n   Average MW Per Plant  Generation (GWh)  \\n0                  15.3             10826  \\n1                  22.5              2550  \\n2                  21.6               557  \\n3                   7.9               590  \\n4                   5.9               235  '}]\n",
      "{\n",
      "  \"id\": \"chatcmpl-7ePeCD1OdJjD4lmYW4kFKBvq8VkGz\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1689866064,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The head of the dataframe includes the following columns: 'State', 'Number of Solar Plants', 'Installed Capacity (MW)', 'Average MW Per Plant', and 'Generation (GWh)'. The values in these columns for the first five rows are as follows:\\n\\nState: California, Arizona, Nevada, New Mexico, Colorado\\nNumber of Solar Plants: 289, 48, 11, 33, 20\\nInstalled Capacity (MW): 4395, 1078, 238, 261, 118\\nAverage MW Per Plant: 15.3, 22.5, 21.6, 7.9, 5.9\\nGeneration (GWh): 10826, 2550, 557, 590, 235\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 160,\n",
      "    \"completion_tokens\": 159,\n",
      "    \"total_tokens\": 319\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load example df raw github\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/solar.csv\") \n",
    "\n",
    "function_specs = [\n",
    "    FunctionSpec(\n",
    "        func_ref=df.head,\n",
    "        parameters=extract_function_metadata(df.head)\n",
    "    ),\n",
    "    FunctionSpec(\n",
    "        func_ref=df.tail,\n",
    "        parameters=extract_function_metadata(df.tail)\n",
    "    ),\n",
    "    FunctionSpec(\n",
    "        func_ref=df.describe,\n",
    "        parameters=extract_function_metadata(df.describe)\n",
    "    )\n",
    "]\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "openai_service = OpenAIService(openai, function_specs=function_specs)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the head of the dataframe?\"}\n",
    "]\n",
    "\n",
    "response = openai_service.call_function(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptsmartfunc",
   "language": "python",
   "name": "gptsmartfunc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
